# 第7章：微调模型以遵循指令

- [create-preference-data-ollama.ipynb](create-preference-data-ollama.ipynb): 一个使用Llama 3.1和Ollama创建偏好微调数据集的合成数据集的notebook

- [dpo-from-scratch.ipynb](dpo-from-scratch.ipynb): 这个notebook实现了用于LLM对齐的直接偏好优化（DPO）


